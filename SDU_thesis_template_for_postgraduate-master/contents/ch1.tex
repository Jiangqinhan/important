% !Mode:: "TeX:UTF-8"
\chapter{绪论}
\echapter{Introduction}

\section{研究背景及研究意义}
\esection{Research background and significance}
随着世界经济和科学技术的飞速发展, 使用手机或电脑去购物, 浏览新闻, 阅读交流的现象越来越普遍. 同时, 在国家提出的"全面推进'互联网+', 打造数字经济新优势"的口号下, 我国的互联网相关行业快速发展并且空前繁荣, 
其中短视频, 网络购物等领域的发展势头尤为突出. 但随之而来的问题便是网络信息的膨胀. 网店, 电商平台, 自媒体, 公众号, up主, 主播如雨后春笋一般, 每时每刻都在产生大量的新内容. 因而海量的信息成了用户们筛选信息的挑战, 用户会发现从海量信息中发现和筛选出有用的感兴趣的信息越来越困难. 推荐系统就是解决该问题的有力武器, 它会根据用户过往的历史信息以及当前环境的热点来预测用户的需求并且将用户需要的商品或信息, 输送到用户面前. 一个有效的推荐系统, 不仅可以给用户个性化推荐, 实现"千人千面", 便利人们的生活, 还可以为公司带来大量的收益. 此外推荐系统也推动了分布式计算, 机器学习, 深度学习等领域的发展, 并且提供落地场景, 常见的机器学习, 深度学习算法, Map Reduce, Spark, Parameter Server等分布式计算框架都在推荐领域得到了广泛的应用. 最重要的是推荐系统显著降低了信息筛选的难度,提高了资源的利用效率. 
\esection{research status at home and abroad}
\section{国内外研究现状}
\subsection{协同过滤}
协同过滤于Using Collaborative Filtering to Weave an Information TapestryCOMMUN ACM, 1992被提出.是推荐算法中出现最早也是最经典的算法, 同时也对业界产生了深远的影响, 即使在现在也有十分广泛的应用. 协同过滤主要有基于用户的协同过滤和基于产品的协同过滤. 协同过滤的本质是根据用户过去的喜好以及其他与该用户相似的用户的选择去给用户推荐商品. 它是一种只有记忆性没有拓展性的推荐算法. 下面以基于用户的协同过滤为例, 介绍其原理.
基于用户的协同过滤是通过计算用户之间的相似度,找出与目标用户相似的用户, 并且从他们的历史行为中, 找出目标用户尚未交互过的物品. 计算相似度的方法有很多, 例如余弦相似度, Jaccard相似度, 皮尔逊相关系数等. 这里以Jaccard相似度为例, 计算公式如下
\begin{equation}
	\operatorname{sim}_{u v}=\frac{|N(u) \cap N(v)|}{|N(u) \cup N(v)|}
\end{equation}
其中$sim_{uv}$表示用户u和用户v的相似度, $N(u)$和$N(v)$表示用户交互过的物品的集合. 在得到用户的相似度后, 找出与目标用户最相近的n个用户, 进而得到潜在的待推荐物品序列, 最后根据目标用户对未交互物品的偏好程度得分来推荐合适的物品, 下面给出一种可能的偏好程度计算公式
\begin{equation}
	R_{u, \mathrm{p}}=\frac{\sum_{\mathrm{s} \in S}\left(w_{\mathrm{u}, \mathrm{s}} \cdot R_{\mathrm{s}, \mathrm{p}}\right)}{\sum_{\mathrm{s} \in S} w_{\mathrm{u}, \mathrm{s}}}
\end{equation}
这里权重$w$可以是两个用户的相似度也可以是其他的加权方式, $R_{s,p}$是用户$s$对物品$p$的评分.
\subsection{线性回归和因子分解机(FM算法)}
线性回归堪称最经典也是最常用的统计算法, 在以神经网络为代表的深度学习算法快速发展之前, 线性回归是主流的推荐算法. 它有诸多优点, 原理简单, 可解释性强, 易于并行能满足线上业务的需求. 线性回归模型也以记忆性为主而缺乏拓展性的模型. 即无法实现个性化推荐, 在热点信息迭代迅速的现在, 并不能满足需求.
因子分解机(FM模型)2010 IEEE International Conference on Data Mining　　Steffen Rendle　　Department of Reasoning for Intelligence　　The Institute of Scientific and Industrial Research Osaka University, Japan. 是在线性回归的基础上发展出来的算法. FM模型是推荐算法的"瑞士军刀"既可以用于排序也可以用于召回, 且其中使用的嵌入向量, 即统计中的隐变量是推荐算法中最重要的概念, 也是算法拓展性的根源. 下面将详细介绍FM算法
在推荐系统中一类很重要的特征是特征组合, 以线性模型为例
\begin{equation}
	y=w_{0}+\sum_{i=1}^{n} w_{i} x_{i}+\sum_{i=1}^{n-1} \sum_{i+1}^{n} w_{i j} x_{i} x_{j}
\end{equation}
其中最后一项便是组合特征, 但是在推荐系统领域, 数据是高度稀疏的, 即很多特征组合并不会在数据中出现因此有相当多的$w{ij}$无法得到训练. 为解决这个问题, FM算法应运而生.
\begin{equation}
	y=w_{0}+\sum_{i=1}^{n} w_{i} x_{i}+\sum_{i=1}^{n} \sum_{i+1}^{n}<v_{i}, v_{j}>x_{i} x_{j}
\end{equation}
不难看出, FM模型相比于线性模型唯一的改动就是将$w_{ij}$替换成了两个向量内积的形式, 这样即使某一个特征组合从未在数据集中出现, 但是只要这两个特征单独出现过, $v_i$,$v_j$就能得到学习的机会. 此外应用完全平方公式便可将最后一项的$O(N^2)$复杂度降低到$O(N)$. 因而, 该算法也能轻易满足线上实时推荐的需求. 此外, 这里的$v_{i}$就是嵌入变量(embedding vector), 广泛应用到后来的所有模型中.
在推荐系统中除了模型的记忆性, 模型的拓展性也是十分重要的.  拓展的主要手段, 就是将粗粒度的特征, 分解成细粒度的特征, 例如饺子和火鸡看起来是毫不相干的东西, 但是如果根据生活常识将这两个名词拆解, 会发现首先, 这两者都是食物, 其次, 这两者都与节日相关, 因此饺子和火鸡其实是有诸多相似之处的. 反应到算法中去, FM模型将线性模型的$w_{ij}$变为$<v_i,v_j>$即将两个特征先拆分为两个向量, 对应上述的细粒度特征, 然后进行内积运算.
\subsection{神经网络}
以神经网络为首的深度学习算法在当今的推荐系统领域处于主导地位.
Heng-Tze Cheng, Levent Koc等人提出了Wide\&Deep模型并将其用于Google app store的推荐业务，Wide\&Deep将传统的线性回归方法与全连接神经网络相结合，其中Wide侧为线性回归模型，强调模型的记忆性. Deep侧为由embedding层与全连接层构成的神经网络，强调模型的拓展性. 
Huifeng Guo, Ruiming Tang等人提出DeepFM模型，DeepFM模型在Wide\&Deep
的基础上, 将wide侧的线性回归模型变为FM模型，FM模型用对应embedding向量的内积代替线性回归中特征交叉项的系数, 克服了高度稀疏数据难以训练的问题. 且FM模型针对交叉项的计算复杂度可达到O(N)量级，极大提高计算效率. 
Guorui Zhou，Chengru Song等人提出Din模型, 将attention机制引入到推荐领域.
在电商的业务场景下，用户的购买历史是一个不定长的序列, 通常的做法是将购买历史序列的信息转换为embedding向量，后经由池化层得到一个固定维度的向量，表示历史行为信息，但是不同历史行为的重要程度应当有所区别，Din引入attention机制，用历史行为的embedding向量与待推荐产品的embedding向量计算求和权重. Din模型曾被用于淘宝商城推荐.
Guorui Zhou, Na Mou等人提出了Dien模型，DIEN则通过GRU单元提取用户兴趣随时间变化的过程. GRU为LSTM的一种改进，产生于nlp领域，其主要作用是提高网络的长期记忆力. DIEN模型借用了NLP领域的方法，与上述模型相比更加注重用户历史行为的时序性.






























